# サイト上の情報をCSVに抽出

## 概要

Robotic Crowd Agentを使って、ウェブサイトの取得したいデータを抽出してCSVに作成する方法を説明します。

事前に、Chrome に Robotic Crowd Agent という拡張機能をインストールしている必要があります。 インストール方法は、[こちら](https://tutorial.co.jp/news/release/2019/06/rc_agent/#install) をご覧ください。

では、始めましょう。

### このチュートリアルのゴール

今回は、株式会社チュートリアルのブログの「日付」「タイトル」「ブログ分類名」の3つのデータを抽出し、CSVにダウンロードします。

### 作業

手順

1. レコーディングを開始するサイトを開く
2. Robotic Crowd Agent のポップアップを表示して、EXTRACT DATAボタンでデータ抽出を開始する
3. 抽出操作を開始する
4. STOPボタンでデータ抽出を停止する
5. データをCSVにダウンロードする

### 1. レコーディングを開始するサイトを開く

はじめに、株式会社チュートリアルのブログページ（[https://tutorial.co.jp/blog/](https://tutorial.co.jp/blog/)\) を開いてください。

![&#x4F1A;&#x793E;&#x30D6;&#x30ED;&#x30B0;&#x30DA;&#x30FC;&#x30B8;](../.gitbook/assets/csv1.png)

Chrome のアドレスバー右側にある、猫のマークをクリックしてください。 すると、下図のように、ポップアップが表示されます。

![nekoclick](../.gitbook/assets/csv2.png)

### 2. Robotic Crowd Agent のポップアップを表示して、EXTRACT DATAボタンでデータの抽出を開始する

前回は「REC」を使用しましたが、今回は「EXTRACT DATA」を使用します。 「EXTRACT DATA」をクリックしてください。

![EXTRACTDATA](../.gitbook/assets/csv3.png)

「EXTRACT DATA」をクリックすると下図のように、 ページ左上に使い方の説明が表示されますので、その説明にしたがって操作していきましょう。

![EXTRACT&#x8AAC;&#x660E;](../.gitbook/assets/csv4.png)

### 3. 抽出操作を開始する

はじめに、ブログの日付を抽出します。 更新日時の部分にカーソルを合わせて、クリックしてください。

![&#x65E5;&#x4ED8;&#x30AF;&#x30EA;&#x30C3;&#x30AF;](../.gitbook/assets/csv5.png)

更新日時の部分をクリックすると、下図が表示されます。 Data Nameの部分に「日付」と入力し、次へを押してください。

![Dataname](../.gitbook/assets/csv6.png)

最新記事の更新日時の部分が青く囲まれたことが分かります。 連続したデータを抽出したいので、「次にどこのデータを連続して抽出すれば良いのか」をロボットに示す必要があります。 そのため、2つ目のブログの更新日時をクリックしてください。

![&#x65E5;&#x4ED8;&#x62BD;&#x51FA;2&#x56DE;&#x76EE;](../.gitbook/assets/csv7.png)

クリックすると、再び下図のものが表示されます。  
Data Nameの部分に、すでに日付というものが入力されています。そのまま次へを押してください。

「次にどこのデータを連続して抽出すれば良いのか」をロボットに示すために日付を2回抽出しましたが、サイトによっては1回抽出すれば全て青く囲まれる場合もあります。 その場合は、2回抽出する必要はありません。

![Dataname2&#x56DE;&#x76EE;](../.gitbook/assets/csv8.png)

このページ全てのブログの更新日時の部分が、青く囲まれました。

＊今回は「次にどこのデータを連続して抽出すれば良いのか」をロボットに示すために日付を2回抽出しましたが、サイトによっては1回抽出すれば全て青く囲まれる場合もあります。その場合は、2回抽出する必要はありません。

次に、ブログタイトルを抽出します。抽出方法はこれまでと同様です。ブログタイトルの部分にカーソルを合わせてクリックしてください。

![&#x30BF;&#x30A4;&#x30C8;&#x30EB;&#x62BD;&#x51FA;](../.gitbook/assets/csv9.png)

ブログタイトルの部分をクリックすると、Data Nameを入力する画面が表示されます。 Data Nameの部分にすでに「日付」と入力されていますが、 今回抽出したいデータはタイトルなので、DataNameを「タイトル」に書き換えてください。 書き換えましたら、次へを押してください。

![&#x30BF;&#x30A4;&#x30C8;&#x30EB;Dataname](../.gitbook/assets/csv10.png)

最後に、ブログ分類名を抽出します。抽出方法はこれまでと同様です。

ブログ分類名の部分にカーソルを合わせてクリックしてください。

![&#x5206;&#x985E;&#x540D;&#x62BD;&#x51FA;](../.gitbook/assets/csv11.png)

クリックするとData Nameの画面が出てきます。

Deta Nameの部分にすでに「タイトル」が入力されていますが、今回抽出したいデータはブログ分類名なので、Data Nameを「ブログ分類名」に書き換えてください。書き換えましたら、次へを押してください。

![&#x5206;&#x985E;&#x540D;Dataname](../.gitbook/assets/csv12.png)

次へを押すと、このページにある全ブログの「日付」「タイトル」「ブログ分類名」が青く囲まれていることがわかります。 現在の画面は以下のようになっています。

![&#x62BD;&#x51FA;&#x524D;&#x78BA;&#x8A8D;](../.gitbook/assets/csv13.png)

### 4. STOPボタンでデータの抽出を停止する

データは全て抽出できました。 データの抽出を停止します。猫のマークをクリックして「STOP」ボタンを押してください。

![nekostop](../.gitbook/assets/csv14.png)

「STOP」を押すと、操作が記録されていることがわかります。

「COPY」を押してテキストエディタ等に貼り付けて全体のワークフローを確認してみてください。  
\(「Robotic Crowd Agentで既存のワークフローを実行する」という記事で使用しますので、テキストエディタ等に保存しておくと便利です。\)

それでは「TRY」をクリックして、確認してみましょう。

![nekostop](../.gitbook/assets/csv15.png)

### 5. データをCSVにダウンロードする

「TRY」を押すと、データを抽出できていることがわかります。

最後に、抽出したデータをCSVにダウンロードしましょう。右下にある「ダウンロードCSV」をクリックしてください。

![&#x30C0;&#x30A6;&#x30F3;&#x30ED;&#x30FC;&#x30C9;CSV](../.gitbook/assets/csv16.png)

ダウンロードCSVをクリックすると、先ほどの抽出されたデータがCSVにダウンロードされたことがわかります。設定したDataNameの「日付」「タイトル」「ブログ分類名」もヘッダーに入力されています。

![CSV&#x62BD;&#x51FA;](../.gitbook/assets/csv17.png)

お疲れ様でした。

今回記録されたワークフローは「Robotic Crowd Agentで既存のワークフローを実行する」という記事の際に使用しますので、テキストエディタ等に保存しておくと便利です。

ウェブサイトのデータをCSVに抽出する方法について説明しました。複数のデータをまとめてCSVに抽出できることがわかったと思います。

今回と同様に似たような作業を繰り返すのは、苦痛に感じると思います。次は、繰り返し作業の記録方法についてご紹介します。

